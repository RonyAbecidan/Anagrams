{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import unittest\n",
    "import numpy as np\n",
    "import itertools\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic of the project\n",
    "\n",
    "### For this second project, I chose to play with strings and I propose to attempt to solve the following problems.\n",
    "\n",
    "Note : During the project, we will apply continuous integration principles using CircleCI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- We consider words composed of lowercase alphabetic characters, separated by  a new line and we are interested in finding the 5 largest anagram groups\n",
    "\n",
    "### Example :\n",
    "\n",
    "#### Input\n",
    "- undisplayed\n",
    "- trace\n",
    "- tea\n",
    "- singleton\n",
    "- eta\n",
    "- eat\n",
    "- displayed\n",
    "- crate\n",
    "- cater\n",
    "- carte\n",
    "- caret\n",
    "- beta\n",
    "- beat\n",
    "- bate\n",
    "- ate\n",
    "- abet\n",
    "\n",
    "#### Output\n",
    "\n",
    "- Group of size 5: caret carte cater crate trace .\n",
    "- Group of size 4: abet bate beat beta .\n",
    "- Group of size 4: ate eat eta tea .\n",
    "- Group of size 1: displayed .\n",
    "- Group of size 1: singleton .\n",
    "\n",
    "Source of this problem : http://poj.org/problem?id=2408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### In order to solve this problem we will apply the oriented object principle learned in course.\n",
    "\n",
    "I propose to consider the following classes.\n",
    "\n",
    "The Class <strong>Word</strong> will represent a word . We can imagine the following methods.\n",
    "\n",
    "- A method shuffle able to shuffle the letters in a word (useful for unitest)\n",
    "- A method is_anagram able to tell us if a word is an anagram of an other one\n",
    "\n",
    "The Class <strong>Dictionary</strong> will represent a dictionary constructed with a set of words inside which, there are anagrams. We can imagine the following methods:\n",
    "\n",
    "- A method remove able to remove a word in a dictionary\n",
    "- A method is_in_the_dictionary able to tell if a word is inside the dictionary we consider or not\n",
    "- A method groups_of_anagrams able to find all the groups of anagrams included in the dictionary we consider.\n",
    "\n",
    "The Class <strong>Problem</strong> will be used to resolve a problem of this type with a .txt file. We can imagine the following methods:\n",
    "- A method parse able to transform a .txt file into a dictionary of words if it respects the format given by the statement\n",
    "- A method resolve which use the .txt file in order to solve the problem (so it returns the groups of anagrams of the dictionary defined by the .txt file)\n",
    "\n",
    "The Class <strong>TestMethods1</strong> will be used to check the good working of our methods from the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self,word):\n",
    "        self.string = word\n",
    "        \n",
    "    ''' To check if two words are anagram of each other we will procede like this :\n",
    "\n",
    "    First, we check if they have the same length. If it's the case...\n",
    "    \n",
    "    We take the first letter of the first word and we check if it's present in the second one.\n",
    "    \n",
    "    If it's not, we can conclude that the two words aren't anagrams \n",
    "    \n",
    "    If it's the case, we delete the first occurence of the letter considered in the second word and we continue with the\n",
    "\n",
    "    next letter of the first word. \n",
    "    \n",
    "    Finally, we continue like that until the end of the first word considered.\n",
    "    \n",
    "    Note : We will not take in account the uppercase for this exercise and so we will consider that\n",
    "    two words made of the exact same letters (even if some of them are maybe uppercase) are anagrams\n",
    "    '''\n",
    "        \n",
    "    def is_anagram(self, word):\n",
    "        first = self.string.lower()\n",
    "        second = word.string.lower()\n",
    "        length_1 = len(first)\n",
    "        length_2 = len(second)\n",
    "        result = False\n",
    "\n",
    "        if length_1 == length_2:\n",
    "            for i in range(0, length_1):\n",
    "                if first[i] in second:\n",
    "                    result = True\n",
    "                    # We remove the first apparition of s1[i] in s2\n",
    "                    second = second.replace(first[i], '', 1)\n",
    "                else:\n",
    "                    result = False\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    def shuffle(self):\n",
    "        # random.shuffle works on list so we decompose our word in a list of\n",
    "        # letters\n",
    "        s_list = list(self.string)\n",
    "        rd.shuffle(s_list)\n",
    "        string = \"\".join(s_list)\n",
    "        word = Word(string)  # and then we recompose the word\n",
    "        return word\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.string\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self,list_of_words):\n",
    "        self.low = list_of_words\n",
    "        \n",
    "    def remove(self,word):\n",
    "        list_of_words=self.low\n",
    "        d_list=[w.string for w in list_of_words]\n",
    "        if word.string in d_list:\n",
    "            index=d_list.index(word.string)\n",
    "            del list_of_words[index]\n",
    "            self.low=list_of_words\n",
    "    \n",
    "    def is_in_the_dictionary(self,word):\n",
    "        list_of_words=self.low\n",
    "        d_list=[w.string for w in list_of_words]\n",
    "        if word.string in d_list:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    ''' To find the group of anagrams we will procede like this :\n",
    "     \n",
    "     First, we create a copy of our dictionary.\n",
    "     Then, for every word w of the initial dictionary,\n",
    "         we are looking for all the words of the copied dictonary which are anagrams of the word w\n",
    "         then,we put them into a list and we print them as wanted.\n",
    "         \n",
    "     In order to not have doublons at the end, we consider at each loop a list which we will contain,\n",
    "     all the words which are anagrams of the current word w. At the end of the research of anagrams for \n",
    "     this word, we erase their existence in the copied dictionary.\n",
    "     \n",
    "     And, in order to not considered an anagram of a word already treated, we execute the loop only if \n",
    "     the word for which we are looking for anagrams is in the copied dictionary.\n",
    "     \n",
    "     Furthemore, at the end, we have to return only the 5 largest groups of anagrams.\n",
    "         \n",
    "    '''\n",
    "        \n",
    "    def groups_of_anagrams(self):\n",
    "        groups=[]\n",
    "        copy_low=self.low.copy()\n",
    "        copy=Dictionary(copy_low)\n",
    "        for word in self.low:\n",
    "            if copy.is_in_the_dictionary(word):\n",
    "                group=[]\n",
    "                to_remove=[]\n",
    "                for other_word in copy.low:\n",
    "                    if other_word.is_anagram(word):\n",
    "                        group.append(other_word)\n",
    "                        to_remove.append(other_word)\n",
    "                groups.append(group)\n",
    "            for word_to_remove in to_remove:\n",
    "                copy.remove(word_to_remove)\n",
    "                \n",
    "        groups_length=np.array([len(group) for group in groups])\n",
    "        indexes=groups_length.argsort()[::-1][:5] #5 biggest elements of groups_length\n",
    "        str=''\n",
    "        for index in indexes:\n",
    "             str=str+f\"Group of size {groups_length[index]} : {groups[index]} \\n\"\n",
    "        return str\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try with the example given in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 5 : [trace, crate, cater, carte, caret] \n",
      "Group of size 4 : [beta, beat, bate, abet] \n",
      "Group of size 4 : [tea, eta, eat, ate] \n",
      "Group of size 1 : [displayed] \n",
      "Group of size 1 : [singleton] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "l=[\"trace\",\"tea\",\"singleton\",\"eta\",\"eat\",\"displayed\",\"crate\",\"cater\",\"carte\",\"caret\",\"beta\",\"beat\",\"bate\",\"ate\",\"abet\"]\n",
    "dictionary=Dictionary([Word(i) for i in l])\n",
    " \n",
    "print(dictionary.groups_of_anagrams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to consider that the input is not directly an object from the class Dictionary but rather a .txt file.\n",
    "\n",
    "Each word will be separated by a new line as suggested in the question.\n",
    "\n",
    "So, we need parser !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    def __init__(self,filename):\n",
    "        self.filename=filename\n",
    "    \n",
    "    def parse(self,path = 'Oracles_1'):\n",
    "         try:\n",
    "            file = open(f\"{path}/{self.filename}.txt\", \"r\")\n",
    "            number_of_words=len(file.readlines())\n",
    "            file.seek(0)\n",
    "            list_of_strings=[]\n",
    "            for i in range(0,number_of_words):\n",
    "                   list_of_strings.append(file.readline().replace('\\n',''))\n",
    "            file.close()\n",
    "            return Dictionary([Word(i) for i in list_of_strings])\n",
    "         except: \n",
    "            print(\"Please check the file (even it's name) , there is something wrong\")\n",
    "    \n",
    "    def resolve_str(self,path='Oracles_1'):\n",
    "        dictionary=self.parse(path)\n",
    "        if dictionary!=None:\n",
    "            return dictionary.groups_of_anagrams() #for the unittest\n",
    "\n",
    "    def resolve(self,path='Oracles_1'):\n",
    "        if self.resolve_str(path)!=None:\n",
    "            print(self.resolve_str(path)) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test it with the same dictionary as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 5 : [trace, crate, cater, carte, caret] \n",
      "Group of size 4 : [beta, beat, bate, abet] \n",
      "Group of size 4 : [tea, eta, eat, ate] \n",
      "Group of size 1 : [displayed] \n",
      "Group of size 1 : [singleton] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem=Problem('Oracle1')\n",
    "problem.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply it to a larger dictionary of words.\n",
    "\n",
    "For instance, I propose to test it with some .txt files which are provided on the repo https://github.com/first20hours/google-10000-english\n",
    "\n",
    "(used as a submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 4 : [care, race, acer, acre] \n",
      "Group of size 4 : [edit, diet, tied, tide] \n",
      "Group of size 4 : [isp, psi, sip, ips] \n",
      "Group of size 4 : [post, stop, spot, tops] \n",
      "Group of size 4 : [spa, asp, sap, pas] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_1=Problem('google-10000-english')\n",
    "problem_1.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 2 : [procedure, reproduce] \n",
      "Group of size 2 : [introduces, reductions] \n",
      "Group of size 2 : [permission, impression] \n",
      "Group of size 2 : [reduction, introduce] \n",
      "Group of size 2 : [statement, testament] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_2=Problem('google-10000-english-usa-no-swears-long')\n",
    "problem_2.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 3 : [meals, salem, males] \n",
      "Group of size 3 : [garden, danger, grande] \n",
      "Group of size 3 : [center, recent, centre] \n",
      "Group of size 3 : [least, tales, steal] \n",
      "Group of size 3 : [fears, fares, safer] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_3=Problem('google-10000-english-usa-no-swears-medium')\n",
    "problem_3.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 4 : [post, stop, spot, tops] \n",
      "Group of size 4 : [care, race, acer, acre] \n",
      "Group of size 4 : [spa, asp, sap, pas] \n",
      "Group of size 4 : [edit, diet, tied, tide] \n",
      "Group of size 4 : [step, pets, sept, pest] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_4=Problem('google-10000-english-usa')\n",
    "problem_4.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to work !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x199e4f3dda0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestMethods1(unittest.TestCase):\n",
    "\n",
    "    def test_is_anagram(self):\n",
    "        word_1 = Word('ChanCe')\n",
    "        word_2 = Word('chnaec')\n",
    "        word_3 = Word('kangaroo')\n",
    "        word_4 = Word('KgroOanao')\n",
    "        word_5 = Word('pneumonoultramicroscopicsilicovolcanoconiosis')\n",
    "        word_6 = word_5.shuffle()\n",
    "        word_7 = Word('Entertainment')\n",
    "        word_8 = Word('Somethingelse')\n",
    "        self.assertEqual(word_1.is_anagram(word_2), True)\n",
    "        self.assertEqual(word_3.is_anagram(word_4), False)\n",
    "        self.assertEqual(word_5.is_anagram(word_6), True)\n",
    "        self.assertEqual(word_7.is_anagram(word_8), False)\n",
    "\n",
    "    def test_groups_of_ancagrams(self):\n",
    "        l=[\"trace\",\"tea\",\"singleton\",\"eta\",\"eat\",\"displayed\",\"crate\",\"cater\",\"carte\",\"caret\",\"beta\",\"beat\",\"bate\",\"ate\",\"abet\"]\n",
    "        dictionary=Dictionary([Word(i) for i in l])\n",
    "        s='Group of size 5 : [trace, crate, cater, carte, caret] \\nGroup of size 4 : [beta, beat, bate, abet] \\nGroup of size 4 : [tea, eta, eat, ate] \\nGroup of size 1 : [displayed] \\nGroup of size 1 : [singleton] \\n'\n",
    "        self.assertEqual(dictionary.groups_of_anagrams()==s, True)\n",
    "        \n",
    "    def test_resolve(self):\n",
    "        example=Problem('Oracle1')\n",
    "        self.assertEqual(example.resolve_str()=='Group of size 5 : [trace, crate, cater, carte, caret] \\nGroup of size 4 : [beta, beat, bate, abet] \\nGroup of size 4 : [tea, eta, eat, ate] \\nGroup of size 1 : [displayed] \\nGroup of size 1 : [singleton] \\n', True)\n",
    "  \n",
    "unittest.main(argv=[''], verbosity=1, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2 - We want a program that will read in a dictionary and a list of phrases and determine which words from the dictionary, if any, form anagrams of the given phrases.\n",
    "\n",
    "The program must find all sets of words in the dictionary which can be formed from the letters in each phrase. We will not include the set consisting of the original words. \n",
    "\n",
    "If no anagram is present, do not write anything, not even a blank line.\n",
    "\n",
    "\n",
    "Input will consist of two parts. The first part is the dictionary, the second part is the set of phrases\n",
    "for which you need to find anagrams. Each part of the file will be terminated by a line consisting of a\n",
    "single ‘#’\n",
    "\n",
    "Output will consist of a series of lines. Each line will consist of the original phrase, a space, an equal\n",
    "sign (=), another space, and the list of words that together make up an anagram of the original phrase,\n",
    "separated by exactly one space. These words must appear in alphabetic sequence. \n",
    "\n",
    "The sentences found must appear in alphabetic sequence too\n",
    "\n",
    "### Example :\n",
    "\n",
    "#### Input \n",
    "\n",
    "- ABC\n",
    "- AND\n",
    "- DEF\n",
    "- DXZ\n",
    "- K\n",
    "- KX\n",
    "- LJSRT\n",
    "- LT\n",
    "- PT\n",
    "- PTYYWQ\n",
    "- Y\n",
    "- YWJSRQ\n",
    "- ZD\n",
    "- ZZXY\n",
    "\n",
    "#\n",
    "- ZZXY ABC DEF\n",
    "- SXZYTWQP KLJ YRTD\n",
    "- ZZXY YWJSRQ PTYYWQ ZZXY\n",
    "\n",
    "#### Output\n",
    "\n",
    "SXZYTWQP KLJ YRTD = DXZ K LJSRT PTYYWQ \n",
    "\n",
    "SXZYTWQP KLJ YRTD = DXZ K LT PT Y YWJSRQ\n",
    "\n",
    "SXZYTWQP KLJ YRTD = KX LJSRT PTYYWQ ZD\n",
    "\n",
    "SXZYTWQP KLJ YRTD = KX LT PT Y YWJSRQ ZD\n",
    "\n",
    "Source of this problem : https://onlinejudge.org/index.php?option=onlinejudge&page=show_problem&problem=84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### In order to solve this problem we will used the previous work and, we will continue to use OOP principles\n",
    "\n",
    "In this problem, we can extend the definition or anagrams for sentences. Two sentences made of words from the dictionary (input) are anagrams if they share the same letters.\n",
    "\n",
    "So, we are looking for a way to generate anagrams of a given sentence knowing a dictionary.\n",
    "\n",
    "However, we will consider only the phrases which are ordered in alphabetic sequence. (Ie, the words are ordered according to the alphabetic sequence)\n",
    "\n",
    "This time, I propose to consider words as strings (thus, we will not create a specific class for the words)\n",
    "\n",
    "I propose to consider the following classes.\n",
    "\n",
    "The Class <strong>Sentence</strong> will represent a sentence constructed with a set of words. We can imagine the following methods.\n",
    "\n",
    "- A method shuffle able to shuffle the words in a sentence (useful for unitest)\n",
    "- A method tuple_to_sentence able to transform a tuple of words into a Sentence\n",
    "- A method to_string able to transform the sentence in a string (separating the words with blank)\n",
    "- A method to_sentence able to transform a string with blanks into a sentence made of words\n",
    "- A method is_equivalent able to tell us if two sentences are composed of exactly the same words but not in the same order\n",
    "- A method in_common able to tell us if a word have all its letters in common with a sentence\n",
    "- A method is_anagram able to tell us if a sentence is an anagram of an other one\n",
    "\n",
    "\n",
    "The Class <strong>Dictionary</strong> will represent a dictionary constructed with a set of words. We can imagine the following method:\n",
    "\n",
    "- A method alphabetic which sort the words of the dictionary in alphabetic order.\n",
    "- A method find_sentences which find all the sentences we can built with the words (ordered in alphabetic order) from the dictionary \n",
    "- A method all_anagrams able to give us all the anagrams of a sentence knowing the dictionary\n",
    "\n",
    "\n",
    "The Class <strong>Problem</strong> will be used to resolve a problem of this type with a .txt file. We can imagine the following methods:\n",
    "- A method parse able to transform a .txt file into a dictionary of words if it respects the format given previously\n",
    "- A method resolve which use the .txt file in order to solve the problem (so it returns all the anagrams of a given sentence knowing the dictionary in the .txt file)\n",
    "\n",
    "The Class <strong>TestMethods2</strong> will be used to check the good working of our methods from the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self,list_of_words):\n",
    "        self.low = list_of_words\n",
    "        \n",
    "    def shuffle(self):\n",
    "        low=self.low.copy()\n",
    "        rd.shuffle(low)\n",
    "        new_sentence=Sentence(low)\n",
    "        return new_sentence\n",
    "    \n",
    "    def tuple_to_sentence(self,tup):\n",
    "        low=[]\n",
    "        for i in range(len(tup)):\n",
    "            low.append(tup[i])\n",
    "        self.low=low\n",
    "    \n",
    "    def to_string(self):\n",
    "        if len(self.low)==0:\n",
    "            print('your sentence is the empty sentence')\n",
    "        else:\n",
    "            string=''\n",
    "            for word in self.low:\n",
    "                string+=word+' ' #note that the final string will have a blank at the end (but it's not a probleme here)\n",
    "            return string\n",
    "    \n",
    "    def to_sentence(self,string):\n",
    "        self.low=string.split(sep=\" \")\n",
    "        \n",
    "    def is_equivalent(self,sentence):\n",
    "        low1=self.low.copy()\n",
    "        low2=sentence.low.copy()\n",
    "        low1.sort()\n",
    "        low2.sort()\n",
    "        return (low1==low2)\n",
    "    \n",
    "    def in_common(self,word):\n",
    "        sentence=self.to_string().lower()\n",
    "        word=word.lower() #we don't consider the uppercase\n",
    "        bool=True\n",
    "        for i in range(0,len(word)):\n",
    "            bool=bool and (word[i] in sentence)\n",
    "        return bool\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' To check if two sentences are anagram of each other we will procede like this :\n",
    "     \n",
    "    First, we tranform them into string but, we replace the spaces with nothing : The words are attached to each other.\n",
    "    \n",
    "    Example : Sentence(\"hello world\") becomes \"Helloworld\"\n",
    "    \n",
    "    Then, we procede just as the first problem with the two strings generated before.\n",
    "\n",
    "    We check if they have the same length. If it's the case...\n",
    "    \n",
    "    We take the first letter of the first string and we check if it's present in the second one.\n",
    "    \n",
    "    If it's not, we can conclude that the two sentences aren't anagrams \n",
    "    \n",
    "    If it's the case, we delete the first occurence of the letter considered in the second string and we continue with the\n",
    "\n",
    "    next letter of the first string. \n",
    "    \n",
    "    Finally, we continue like that until the end of the first string considered.\n",
    "    \n",
    "    Note : We will not take in account the uppercase for this exercise and so we will consider that\n",
    "    two sentences made of the exact same letters (even if some of them are maybe uppercases) are anagrams\n",
    "    '''\n",
    "    \n",
    "    def is_anagram(self,Sentence2):\n",
    "        first=self.to_string().replace(\" \",\"\")\n",
    "        second=Sentence2.to_string().replace(\" \",\"\")\n",
    "        length_1 = len(first)\n",
    "        length_2 = len(second)\n",
    "        result = False\n",
    "        \n",
    "        if length_1 == length_2:\n",
    "            for i in range(0, length_1):\n",
    "                if first[i] in second:\n",
    "                    result = True\n",
    "                    # We remove the first apparition of s1[i] in s2\n",
    "                    second = second.replace(first[i], '', 1)\n",
    "                else:\n",
    "                    result = False\n",
    "                    break\n",
    "        return result\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Sentence({str(self.low)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self,list_of_words):\n",
    "        self.low = list_of_words\n",
    "        \n",
    "    def alphabetic(self):\n",
    "        self.low.sort()\n",
    "        \n",
    "    ''' To find all the sentences we can built with the words (ordered in alphabetic order) from the dictionary,\n",
    "     we start to order alphabeticly the dictionary we consider.\n",
    "     \n",
    "     Then, we create all the subsets of words ordered alphabeticly of our dictionary.\n",
    "     \n",
    "     For that, we will use list(itertools.combinations(dictionary, i)) which returns,\n",
    "     all the subsets of words of size i of the dictionary, while preserving the order of the words existing within it. \n",
    "     \n",
    "     This subsets are returned as tuples so we will have to use our function tuple_to_sentence in order to tranform them to sentences.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    def find_sentences(self):\n",
    "        Sentences=[]\n",
    "        self.alphabetic()\n",
    "        dictionary=self.low\n",
    "        for i in range(1,len(dictionary)):\n",
    "            subsets=list(itertools.combinations(dictionary, i))\n",
    "            for j in range(len(subsets)):\n",
    "                sentence=Sentence([''])\n",
    "                sentence.tuple_to_sentence(subsets[j])\n",
    "                Sentences.append(sentence)\n",
    "        return Sentences\n",
    "    \n",
    "    \n",
    "    '''In order to find all the anagrams of a sentence, we will proceed like this :\n",
    "    \n",
    "    - First we create a dictionary made of all the words from our initial dictionary which share all their letters\n",
    "    present in the sentence that we consider\n",
    "    \n",
    "    -Then, we create all the possible sentence from this new dictionary\n",
    "    \n",
    "    - At last, we create a list of anagrams which will contains all the sentences generated before which are anagrams of\n",
    "    the sentence we entered and, which not share the same words with that sentence\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def all_anagrams(self,sentence):\n",
    "        dictionary=self.low\n",
    "        final_dictionary=[]\n",
    "        anagrams=[]\n",
    "        for word in dictionary:\n",
    "            if sentence.in_common(word): #if the word share all its letters with the sentence\n",
    "                final_dictionary.append(word)\n",
    "                \n",
    "        final_dictionary=Dictionary(final_dictionary)\n",
    "        sentences=final_dictionary.find_sentences()\n",
    "        \n",
    "        for s in sentences:\n",
    "            if s.is_anagram(sentence) and not(s.is_equivalent(sentence)): #we don't want to return the same words in the output\n",
    "                anagrams.append(s.to_string())\n",
    "        anagrams.sort()\n",
    "        return anagrams\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    def __init__(self,filename):\n",
    "        self.filename=filename\n",
    "    \n",
    "    def parse(self,path = 'Oracles_2'):\n",
    "         try:\n",
    "            file = open(f\"{path}/{self.filename}.txt\", \"r\")\n",
    "            number_of_lines=len(file.readlines())\n",
    "            file.seek(0)\n",
    "            list_of_words=[]\n",
    "            sentences=[]\n",
    "            cpt=0\n",
    "            current_word=file.readline().replace('\\n','')\n",
    "            while not ('#' in current_word): \n",
    "                list_of_words.append(current_word)\n",
    "                current_word=file.readline().replace('\\n','')\n",
    "                cpt+=1\n",
    "            \n",
    "            for j in range(cpt,number_of_lines-1): #when we start to have the symbol \"#\"...\n",
    "                sentence=Sentence(['']) #...we start considering sentences\n",
    "                string=file.readline().replace('\\n','')\n",
    "                sentence.to_sentence(string)\n",
    "                sentences.append(sentence)\n",
    "            file.close()\n",
    "            return Dictionary(list_of_words),sentences\n",
    "         except: \n",
    "            print(\"Please check the file (even its name) , there is something wrong\")\n",
    "    \n",
    "    def resolve_str(self,path='Oracles_2'):\n",
    "        dictionary,sentences=self.parse(path)\n",
    "        final_result=''\n",
    "        if dictionary!=None:\n",
    "            for i in range(len(sentences)):\n",
    "                all_anagrams=dictionary.all_anagrams(sentences[i])\n",
    "                for j in range(len(all_anagrams)):\n",
    "                    final_result=final_result + f\"{sentences[i].to_string()} =  {all_anagrams[j]}\" + \"\\n\" \n",
    "        return final_result\n",
    "                \n",
    "    def resolve(self,path='Oracles_2'):\n",
    "        if self.resolve_str(path)!=None:\n",
    "            print(self.resolve_str(path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SXZYTWQP KLJ YRTD  =  DXZ K LJSRT PTYYWQ \n",
      "SXZYTWQP KLJ YRTD  =  DXZ K LT PT Y YWJSRQ \n",
      "SXZYTWQP KLJ YRTD  =  KX LJSRT PTYYWQ ZD \n",
      "SXZYTWQP KLJ YRTD  =  KX LT PT Y YWJSRQ ZD \n",
      "\n"
     ]
    }
   ],
   "source": [
    "P=Problem('example')\n",
    "P.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.034s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1b7cc661fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestMethods1(unittest.TestCase):\n",
    "\n",
    "    def test_to_string(self):\n",
    "        first_sentence=Sentence(['Hello','my','name','is','john'])\n",
    "        self.assertEqual(first_sentence.to_string(),\"Hello my name is john \")\n",
    "        \n",
    "    def test_to_sentence(self):\n",
    "        string='Hello my name is john'\n",
    "        sentence=Sentence([''])\n",
    "        sentence.to_sentence(string)\n",
    "        self.assertEqual(sentence.to_string(),string+' ')\n",
    "\n",
    "    def test_in_common(self):\n",
    "        first_sentence=Sentence(['Hello','my','name','is','john'])\n",
    "        word1 = \"hello\"\n",
    "        word2 = \"abracadabra\"\n",
    "        self.assertEqual(first_sentence.in_common(word1), True)\n",
    "        self.assertEqual(first_sentence.in_common(word2), False)\n",
    "        \n",
    "    def is_equivalent(self):\n",
    "        sentence1=Sentence(['Hello','my','name','is','john'])\n",
    "        sentence2=Sentence(['Hello','my','name','is','barbara'])\n",
    "        self.assertEqual(sentence1.is_equivalent(sentence2), False)\n",
    "        self.assertEqual(sentence1.is_equivalent(sentence1.shuffle()), False)\n",
    "        \n",
    "    def test_is_anagram(self):\n",
    "        Sentence1=Sentence([\"SXZYTWQP\",\"KLJ\",\"YRTD\"])\n",
    "        Sentence2=Sentence([\"DXZ\",\"K\",\"LJSRT\",\"PTYYWQ\"])\n",
    "        Sentence3=Sentence(['Hello','my','name','is','john'])\n",
    "        Sentence4=Sentence1.shuffle()\n",
    "        self.assertEqual(Sentence1.is_anagram(Sentence2),True)\n",
    "        self.assertEqual(Sentence2.is_anagram(Sentence3),False)\n",
    "        self.assertEqual(Sentence2.is_anagram(Sentence4),True)\n",
    "        \n",
    "    def test_all_anagrams(self):\n",
    "        l=Dictionary([\"ABC\",\"AND\",\"DEF\",\"DXZ\",\"K\",\"KX\",\"LJSRT\",\"LT\",\"PT\",\"PTYYWQ\",\"Y\",\"YWJSRQ\",\"ZD\",\"ZZXY\"])\n",
    "        S=Sentence([\"SXZYTWQP\",\"KLJ\",\"YRTD\"])\n",
    "        self.assertEqual(l.all_anagrams(S),['DXZ K LJSRT PTYYWQ ','DXZ K LT PT Y YWJSRQ ','KX LJSRT PTYYWQ ZD ','KX LT PT Y YWJSRQ ZD '])\n",
    "        \n",
    "    def test_resolve_str(self):\n",
    "        P=Problem('example')\n",
    "        self.assertEqual(P.resolve_str(),'SXZYTWQP KLJ YRTD  =  DXZ K LJSRT PTYYWQ \\nSXZYTWQP KLJ YRTD  =  DXZ K LT PT Y YWJSRQ \\nSXZYTWQP KLJ YRTD  =  KX LJSRT PTYYWQ ZD \\nSXZYTWQP KLJ YRTD  =  KX LT PT Y YWJSRQ ZD \\n')\n",
    "        \n",
    "unittest.main(argv=[''], verbosity=1, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# 3 - Finally, we will try to create a spell checker\n",
    "\n",
    "We will study first, the correction of the mistakes in which all the letters of a word are present, but, not in the good order.\n",
    "\n",
    "### Example :'Cra' instead of 'Car'\n",
    "\n",
    "The program must find such mistakes in a sentence or a paragraph knowing a sets of words in a dictionary.\n",
    "\n",
    "Moreover, I will extend the power of this spell checker in considering the case where some letters are forgotten in a word\n",
    "\n",
    "### Exemple : 'Rom' instead of 'Room'\n",
    "\n",
    "For instance, let's say that we want to also guess a word written by someone in which there are at most 2 letters missing (knowing a dictionary)\n",
    "\n",
    "\n",
    "### Input : A .txt document with first, the words of the dictionary at each line until a line in which there will be the symbol \"#\" which will indicate that we start to consider sentences\n",
    "\n",
    "- Movie\n",
    "- Car\n",
    "- Room\n",
    "- Supermarket\n",
    "- Computer\n",
    "- #\n",
    "- Today, I will go to the supemakret because I need a copmuter for my romo\n",
    "- I am watching a moive from my cra\n",
    "\n",
    "### Output : Proposition of corrections for the sentences\n",
    "\n",
    "Sentence : 'Today, I will go to the supemakret because I need a copmuter for my romo'\n",
    "\n",
    "I find errors, I think the correct answer is :\n",
    "\n",
    "'Today, I will go to the supermarket because I need a computer for my room'\n",
    "\n",
    "Sentence : 'I am watching a moive from my cra'\n",
    "\n",
    "I find errors, I think the correct answer is :\n",
    "\n",
    "'I am watching a movie from my car'\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to solve this problem we will used the previous work and, we will continue to use OOP principles\n",
    "#### Furthermore, we will use the Hamming distance as an indicator of a potential mistake in a sentence (It's a a string metric for measuring a distance between two sequences. More information here : https://en.wikipedia.org/wiki/Hamming_distance)\n",
    "\n",
    "#### We will use this distance in order to guess a word which have at most 2 letters missing\n",
    "\n",
    "#### So, if you remember what we have said before, we will looking for words in the dictionary, for which, the hamming distances between them and the incorrect words of our sentences are lower or equal than 2.\n",
    "\n",
    "I propose to consider the following classes.\n",
    "\n",
    "\n",
    "The Class <strong>Word</strong> will represent a word . We can imagine the following methods.\n",
    "\n",
    "- A method shuffle able to shuffle the letters in a word (useful for unitest)\n",
    "- A method is_anagram able to tell us if a word is an anagram of an other one\n",
    "- A method hamming able to compute the hamming distance between two words\n",
    "- A method correct able to propose correction for a word giving a dictionary\n",
    "\n",
    "The Class <strong>Dictionary</strong> will represent a dictionary constructed with a set of words. We can imagine the following method:\n",
    "\n",
    "- A method list_of_strings able to transform a dictionary made of Words in a list of strings\n",
    "- A method incorrect_words which find all the words of a sentence which are not present in the dictionary\n",
    "\n",
    "The Class <strong>Sentence</strong> will represent a sentence constructed with a set of words. We can imagine the following methods.\n",
    "\n",
    "- A method correct_sentence which will propose all the corrections possible of a sentence giving a dictionary\n",
    "\n",
    "\n",
    "The Class <strong>Problem</strong> will be used to resolve a problem of this type with a .txt file. We can imagine the following methods:\n",
    "- A method parse able to transform a .txt file into a dictionary of words if it respects the format given previously\n",
    "- A method resolve which use the .txt file in order to solve the problem (so it returns all the anagrams of a given sentence knowing the dictionary in the .txt file)\n",
    "\n",
    "The Class <strong>TestMethods3</strong> will be used to check the good working of our methods from the different classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

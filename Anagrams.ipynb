{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic of the project\n",
    "\n",
    "### For this second project, I chose to play with strings and I propose to attempt to solve the following problems.\n",
    "\n",
    "Note : During the project, we will apply continuous integration principles using CircleCI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- We consider words composed of lowercase alphabetic characters, separated by  a new line and we are interested in finding the 5 largest anagram groups\n",
    "\n",
    "### Example :\n",
    "\n",
    "#### Input\n",
    "- undisplayed\n",
    "- trace\n",
    "- tea\n",
    "- singleton\n",
    "- eta\n",
    "- eat\n",
    "- displayed\n",
    "- crate\n",
    "- cater\n",
    "- carte\n",
    "- caret\n",
    "- beta\n",
    "- beat\n",
    "- bate\n",
    "- ate\n",
    "- abet\n",
    "\n",
    "#### Output\n",
    "\n",
    "- Group of size 5: caret carte cater crate trace .\n",
    "- Group of size 4: abet bate beat beta .\n",
    "- Group of size 4: ate eat eta tea .\n",
    "- Group of size 1: displayed .\n",
    "- Group of size 1: singleton .\n",
    "\n",
    "Source of this problem : http://poj.org/problem?id=2408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### In order to solve this problem we will apply the oriented object principle learned in course.\n",
    "\n",
    "I propose to consider the following classes.\n",
    "\n",
    "The Class <strong>Word</strong> will represent a word. We can imagine the following methods.\n",
    "\n",
    "- A method shuffle able to shuffle the letters in a word (useful for unitest)\n",
    "- A method is_anagram able to tell us if a word is an anagram of an other one\n",
    "\n",
    "The Class <strong>Dictionary</strong> will represent a set of words, inside which there are anagrams. We can imagine the following methods:\n",
    "\n",
    "- A method remove able to remove a word in a dictionary\n",
    "- A method is_in_the_dictionary able to tell if a word is inside the dictionary we consider or not\n",
    "- A method groups_of_anagrams able to find all the groups of anagrams included in the dictionary we consider.\n",
    "\n",
    "The Class <strong>Problem</strong> will be used to resolve a problem of this type with a .txt file. We can imagine the following methods:\n",
    "- A method parse able to transform a .txt file into a dictionary of words if it respects the format given by the statement\n",
    "- A method resolve which use the .txt file in order to solve the problem (so it returns the groups of anagrams of the dictionary defined by the .txt file)\n",
    "\n",
    "The Class <strong>TestMethods1</strong> will be used to check the good working of our methods from the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import unittest\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self,word):\n",
    "        self.string = word\n",
    "        \n",
    "    ''' To check if two words are anagram of each other we will procede like this :\n",
    "\n",
    "    First, we check if they have the same length. If it's the case...\n",
    "    \n",
    "    We take the first letter of the first word and we check if it's present in the second one.\n",
    "    \n",
    "    If it's not, we can conclude that the two words aren't anagrams \n",
    "    \n",
    "    If it's the case, we delete the first occurence of the letter considered in the second word and we continue with the\n",
    "\n",
    "    next letter of the first word. \n",
    "    \n",
    "    Finally, we continue like that until the end of the first word considered.\n",
    "    \n",
    "    Note : We will not take in account the uppercase for this exercise and so we will consider that\n",
    "    two words made of the exact same letters (even if some of them are maybe uppercase) are anagrams\n",
    "    '''\n",
    "        \n",
    "    def is_anagram(self, word):\n",
    "        first = self.string.lower()\n",
    "        second = word.string.lower()\n",
    "        length_1 = len(first)\n",
    "        length_2 = len(second)\n",
    "        result = False\n",
    "\n",
    "        if length_1 == length_2:\n",
    "            for i in range(0, length_1):\n",
    "                if first[i] in second:\n",
    "                    result = True\n",
    "                    # We remove the first apparition of s1[i] in s2\n",
    "                    second = second.replace(first[i], '', 1)\n",
    "                else:\n",
    "                    result = False\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    def shuffle(self):\n",
    "        # random.shuffle works on list so we decompose our word in a list of\n",
    "        # letters\n",
    "        s_list = list(self.string)\n",
    "        rd.shuffle(s_list)\n",
    "        string = \"\".join(s_list)\n",
    "        word = Word(string)  # and then we recompose the word\n",
    "        return word\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.string\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self,list_of_words):\n",
    "        self.low = list_of_words\n",
    "        \n",
    "    def remove(self,word):\n",
    "        list_of_words=self.low\n",
    "        d_list=[w.string for w in list_of_words]\n",
    "        if word.string in d_list:\n",
    "            index=d_list.index(word.string)\n",
    "            del list_of_words[index]\n",
    "            self.low=list_of_words\n",
    "    \n",
    "    def is_in_the_dictionary(self,word):\n",
    "        list_of_words=self.low\n",
    "        d_list=[w.string for w in list_of_words]\n",
    "        if word.string in d_list:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    ''' To find the group of anagrams we will procede like this :\n",
    "     \n",
    "     First, we create a copy of our dictionary.\n",
    "     Then, for every word w of the initial dictionary,\n",
    "         we are looking for all the words of the copied dictonary which are anagrams of the word w\n",
    "         then,we put them into a list and we print them as wanted.\n",
    "         \n",
    "     In order to not have doublons at the end, we consider at each loop a list which we will contain,\n",
    "     all the words which are anagrams of the current word w. At the end of the research of anagrams for \n",
    "     this word, we erase their existence in the copied dictionary.\n",
    "     \n",
    "     And, in order to not considered an anagram of a word already treated, we execute the loop only if \n",
    "     the word for which we are looking for anagrams is in the copied dictionary.\n",
    "     \n",
    "     Furthemore, at the end, we have to return only the 5 largest groups of anagrams.\n",
    "         \n",
    "    '''\n",
    "        \n",
    "    def groups_of_anagrams(self):\n",
    "        groups=[]\n",
    "        copy_low=self.low.copy()\n",
    "        copy=Dictionary(copy_low)\n",
    "        for word in self.low:\n",
    "            if copy.is_in_the_dictionary(word):\n",
    "                group=[]\n",
    "                to_remove=[]\n",
    "                for other_word in copy.low:\n",
    "                    if other_word.is_anagram(word):\n",
    "                        group.append(other_word)\n",
    "                        to_remove.append(other_word)\n",
    "                groups.append(group)\n",
    "            for word_to_remove in to_remove:\n",
    "                copy.remove(word_to_remove)\n",
    "                \n",
    "        groups_length=np.array([len(group) for group in groups])\n",
    "        indexes=groups_length.argsort()[::-1][:5] #5 biggest elements of groups_length\n",
    "        str=''\n",
    "        for index in indexes:\n",
    "             str=str+f\"Group of size {groups_length[index]} : {groups[index]} \\n\"\n",
    "        return str\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try with the example given in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 5 : [trace, crate, cater, carte, caret] \n",
      "Group of size 4 : [beta, beat, bate, abet] \n",
      "Group of size 4 : [tea, eta, eat, ate] \n",
      "Group of size 1 : [displayed] \n",
      "Group of size 1 : [singleton] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "l=[\"trace\",\"tea\",\"singleton\",\"eta\",\"eat\",\"displayed\",\"crate\",\"cater\",\"carte\",\"caret\",\"beta\",\"beat\",\"bate\",\"ate\",\"abet\"]\n",
    "dictionary=Dictionary([Word(i) for i in l])\n",
    " \n",
    "print(dictionary.groups_of_anagrams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to consider that the input is not directly an object from the class Dictionary but rather a .txt file.\n",
    "\n",
    "Each word will be separated by a new line as suggested in the question.\n",
    "\n",
    "So, we need parser !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    def __init__(self,filename):\n",
    "        self.filename=filename\n",
    "    \n",
    "    def parse(self,path = 'Oracles_1'):\n",
    "         try:\n",
    "            file = open(f\"{path}/{self.filename}.txt\", \"r\")\n",
    "            number_of_words=len(file.readlines())\n",
    "            file.seek(0)\n",
    "            list_of_strings=[]\n",
    "            for i in range(0,number_of_words):\n",
    "                   list_of_strings.append(file.readline().replace('\\n',''))\n",
    "            file.close()\n",
    "            return Dictionary([Word(i) for i in list_of_strings])\n",
    "         except: \n",
    "            print(\"Please check the name of the file, there is something wrong\")\n",
    "    \n",
    "    def resolve_str(self,path='Oracles_1'):\n",
    "        dictionary=self.parse(path)\n",
    "        if dictionary!=None:\n",
    "            return dictionary.groups_of_anagrams() #for the unittest\n",
    "\n",
    "    def resolve(self,path='Oracles_1'):\n",
    "        if self.resolve_str(path)!=None:\n",
    "            print(self.resolve_str(path)) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test it with the same dictionary as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 5 : [trace, crate, cater, carte, caret] \n",
      "Group of size 4 : [beta, beat, bate, abet] \n",
      "Group of size 4 : [tea, eta, eat, ate] \n",
      "Group of size 1 : [displayed] \n",
      "Group of size 1 : [singleton] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem=Problem('Oracle1')\n",
    "problem.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply it to a larger dictionary of words.\n",
    "\n",
    "For instance, I propose to test it with some .txt files which are provided on the repo https://github.com/first20hours/google-10000-english\n",
    "\n",
    "(used as a submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 4 : [care, race, acer, acre] \n",
      "Group of size 4 : [edit, diet, tied, tide] \n",
      "Group of size 4 : [isp, psi, sip, ips] \n",
      "Group of size 4 : [post, stop, spot, tops] \n",
      "Group of size 4 : [spa, asp, sap, pas] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_1=Problem('google-10000-english')\n",
    "problem_1.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 2 : [procedure, reproduce] \n",
      "Group of size 2 : [introduces, reductions] \n",
      "Group of size 2 : [permission, impression] \n",
      "Group of size 2 : [reduction, introduce] \n",
      "Group of size 2 : [statement, testament] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_2=Problem('google-10000-english-usa-no-swears-long')\n",
    "problem_2.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 3 : [meals, salem, males] \n",
      "Group of size 3 : [garden, danger, grande] \n",
      "Group of size 3 : [center, recent, centre] \n",
      "Group of size 3 : [least, tales, steal] \n",
      "Group of size 3 : [fears, fares, safer] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_3=Problem('google-10000-english-usa-no-swears-medium')\n",
    "problem_3.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group of size 4 : [post, stop, spot, tops] \n",
      "Group of size 4 : [care, race, acer, acre] \n",
      "Group of size 4 : [spa, asp, sap, pas] \n",
      "Group of size 4 : [edit, diet, tied, tide] \n",
      "Group of size 4 : [step, pets, sept, pest] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_4=Problem('google-10000-english-usa')\n",
    "problem_4.resolve('google-10000-english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to work !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x199e4f3dda0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestMethods1(unittest.TestCase):\n",
    "\n",
    "    def test_is_anagram(self):\n",
    "        word_1 = Word('ChanCe')\n",
    "        word_2 = Word('chnaec')\n",
    "        word_3 = Word('kangaroo')\n",
    "        word_4 = Word('KgroOanao')\n",
    "        word_5 = Word('pneumonoultramicroscopicsilicovolcanoconiosis')\n",
    "        word_6 = word_5.shuffle()\n",
    "        word_7 = Word('Entertainment')\n",
    "        word_8 = Word('Somethingelse')\n",
    "        self.assertEqual(word_1.is_anagram(word_2), True)\n",
    "        self.assertEqual(word_3.is_anagram(word_4), False)\n",
    "        self.assertEqual(word_5.is_anagram(word_6), True)\n",
    "        self.assertEqual(word_7.is_anagram(word_8), False)\n",
    "\n",
    "    def test_groups_of_anagrams(self):\n",
    "        l=[\"trace\",\"tea\",\"singleton\",\"eta\",\"eat\",\"displayed\",\"crate\",\"cater\",\"carte\",\"caret\",\"beta\",\"beat\",\"bate\",\"ate\",\"abet\"]\n",
    "        dictionary=Dictionary([Word(i) for i in l])\n",
    "        s='Group of size 5 : [trace, crate, cater, carte, caret] \\nGroup of size 4 : [beta, beat, bate, abet] \\nGroup of size 4 : [tea, eta, eat, ate] \\nGroup of size 1 : [displayed] \\nGroup of size 1 : [singleton] \\n'\n",
    "        self.assertEqual(dictionary.groups_of_anagrams()==s, True)\n",
    "        \n",
    "    def test_resolve(self):\n",
    "        example=Problem('Oracle1')\n",
    "        self.assertEqual(example.resolve_str()=='Group of size 5 : [trace, crate, cater, carte, caret] \\nGroup of size 4 : [beta, beat, bate, abet] \\nGroup of size 4 : [tea, eta, eat, ate] \\nGroup of size 1 : [displayed] \\nGroup of size 1 : [singleton] \\n', True)\n",
    "  \n",
    "unittest.main(argv=[''], verbosity=1, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - We want a program that will read in a dictionary and a list of phrases and determine which words from the dictionary, if any, form anagrams of the given phrases.\n",
    "\n",
    "The program must find all sets of words in the dictionary which can be formed from the letters in each phrase. We will not include the set consisting of the original words. \n",
    "\n",
    "If no anagram is present, do not write anything, not even a blank line.\n",
    "\n",
    "These words must appear in alphabetic sequence.\n",
    "\n",
    "### Example :\n",
    "\n",
    "#### Input \n",
    "\n",
    "ABC\n",
    "AND\n",
    "DEF\n",
    "DXZ\n",
    "K\n",
    "KX\n",
    "LJSRT\n",
    "LT\n",
    "PT\n",
    "PTYYWQ\n",
    "Y\n",
    "YWJSRQ\n",
    "ZD\n",
    "ZZXY\n",
    "ZZXY ABC DEF\n",
    "SXZYTWQP KLJ YRTD\n",
    "ZZXY YWJSRQ PTYYWQ ZZXY\n",
    "\n",
    "#### Output\n",
    "\n",
    "SXZYTWQP KLJ YRTD = DXZ K LJSRT PTYYWQ \n",
    "\n",
    "SXZYTWQP KLJ YRTD = DXZ K LT PT Y YWJSRQ\n",
    "\n",
    "SXZYTWQP KLJ YRTD = KX LJSRT PTYYWQ ZD\n",
    "\n",
    "SXZYTWQP KLJ YRTD = KX LT PT Y YWJSRQ ZD\n",
    "\n",
    "Source of this problem : https://onlinejudge.org/index.php?option=onlinejudge&page=show_problem&problem=84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=Word('SXZYTWQP KLJ YRTD ')\n",
    "u=Word(\"DXZ K LJSRT PTYYWQ\")\n",
    "w.is_anagram(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "#### In order to solve this problem we will used the previous work and, we will continue to use OOP principles\n",
    "\n",
    "In this problem, we can extend the definition or anagrams for sentences. Two sentences made of words from the dictionary (input) are anagrams if they share the same letters.\n",
    "\n",
    "So, we are looking for a way to generate anagrams of a given sentence knowing a dictionary.\n",
    "\n",
    "However, we will consider only the phrases which are ordered in alphabetic sequence. (Ie, the words are ordered according to the alphabetic sequence)\n",
    "\n",
    "I propose to consider the following classes.\n",
    "\n",
    "The Class <strong>Dictionary</strong> will represent a set of words. We can imagine the following method:\n",
    "\n",
    "- A method alphabetic which sort the words of the dictionary in alphabetic order.\n",
    "\n",
    "The Class <strong>Sentence</strong> will represent a sentence. We can imagine the following methods.\n",
    "\n",
    "- A method shuffle able to shuffle the letters in a sentence (useful for unitest)\n",
    "- A method in_common able to tell us if a word have letters in common with a sentence\n",
    "- A method is_anagram able to tell us if a sentence is an anagram of an other one\n",
    "- A methode all_anagrams able to give us all the anagrams of a sentence knowing the reference's dictionary\n",
    "\n",
    "The Class <strong>Problem</strong> will be used to resolve a problem of this type with a .txt file. We can imagine the following methods:\n",
    "- A method parse able to transform a .txt file into a dictionary of words if it respects the format given at the first question\n",
    "- A method resolve which use the .txt file in order to solve the problem (so it returns all the anagrams of a given sentence knowing the dictionary in the .txt file)\n",
    "\n",
    "The Class <strong>TestMethods2</strong> will be used to check the good working of our methods from the different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Finally, we will try to create a spell checker\n",
    "\n",
    "We will study first, the correction of the mistakes in which all the letters of a word are present, but, not in the good order\n",
    "\n",
    "Example :'Cra' instead of 'Car'\n",
    "\n",
    "The program must find such mistakes in a sentence or a paragraph knowing a sets of words in a dictionary.\n",
    "\n",
    "If I have time, I will extends the power of this spell checker in considering the case where some letters are forgotten in a word\n",
    "\n",
    "Exemple : 'Rom' instead of 'Room'\n",
    "\n",
    "\n",
    "#### Input \n",
    "\n",
    "- Dictionary = ['Movie','Car','Room','Supermarket','Computer']\n",
    "- Sentence = 'Today, I will go to the supemakret because I need a copmuter for my romo'\n",
    "\n",
    "#### Output\n",
    "\n",
    "I find 3 errors, I think the correct answer is :\n",
    "\n",
    "'''Today, I will go to the supermarket because I need a computer for my room'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
